{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd000fbe7a0ffdff41cb6153984e119c63b68f43f50190a26a2d6b6229a722be293",
   "display_name": "Python 3.7.10 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preprocessing: Categorical and Numeric Features \n",
    "\n",
    "- Data of a column can be largely divided into the following three types:\n",
    "    1. Numeric: Continuous number, such as age and time\n",
    "    2. Categoric: Discrete values presented either as text (e.g. gender: female/male) or number (e.g. level: 1, 2, 3)\n",
    "    3. Text: Words, sentences of words such as movie review\n",
    "- Apart from item 3, the following discuss the preprocessing of numberic and categorical data\n",
    "\n",
    "## Why preprocessing is needed? \n",
    "\n",
    "### For numberic features:\n",
    "- The need for preprocessing is to \"standardise\" the values of each column and altogether as a whole in terms of means and variance\n",
    "- Refered as scaling, this is to minimise the effects of extremely large or small values (within a and across columns) to affect the training model\n",
    "    - There are many ways to scale numberic values, such as:\n",
    "        - StandardScaler\n",
    "        - RobustScaler\n",
    "        - MinMaxScaler\n",
    "        - Normalizer \n",
    "\n",
    "### For categorical features:\n",
    "- Computer was not able to understand categorical data, such as \"female and male\" or \"level: 1, 2, 3\", if not being \"told\" as a number say, 0 means female and 1 means male\n",
    "- Column of categorical data will need to be \"unpivoted\", making each value become a column title before feeding into a machine learning model, for example:\n",
    "    - \"gender\" column will be divided into \"female\" and \"male\" columns, \n",
    "    - each row of data will be either 1 or 0 under female or male column to indicate its value\n",
    "\n",
    "## ColumnTransfomer\n",
    "- is a way to join all preprocessing of numberic and categorical columns together for preprocessing\n",
    "- method .fit_transform() to be used on the training dataset (X_train)\n",
    "- method .transform() to be used on the test dataset (X_test)\n",
    "- for details please refer to https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe    \n",
    "\n",
    "\n",
    "*first, lets load the libraries and data*\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#for spliting a dataset into training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for transformation, categorical \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#for transformation, numeric \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#concatenate the preprocessing of categorical and numeric functions together to perform transformation\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Read in the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "data = os.path.join(pwd, \"data.csv\")\n",
    "df = pd.read_csv(data)\n",
    "df.head(3)"
   ]
  },
  {
   "source": [
    "### Feature and target selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[\"Pclass\", \"Sex\",\"Fare\"]]\n",
    "target = df[[\"Survived\"]]"
   ]
  },
  {
   "source": [
    "# Categorical Feature\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pclass\n",
       "3         491\n",
       "1         216\n",
       "2         184\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df[[\"Pclass\"]].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sex   \n",
       "male      577\n",
       "female    314\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df[[\"Sex\"]].value_counts(ascending=False)"
   ]
  },
  {
   "source": [
    "# Numeric Feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'There are altogether 248 of fares out of 891 passengers, lets assume these are not categorical for now for demonstration in handling numeric features'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "fare_types = df[[\"Fare\"]].value_counts().count()\n",
    "\n",
    "display(\"There are altogether {} of fares out of {} passengers, lets assume these are not categorical for now to demonstrate preprocessing of numeric features\".format(fare_types, df.shape[0]))"
   ]
  },
  {
   "source": [
    "# Spliting Dataset\n",
    "- This step is to split a dataset into training and testing sets for machine learing:\n",
    "    - training set, named as X_train and y_train, for training a model\n",
    "    - testing set, named as X_test and y_train, for testing/evaluating the performace of a model\n",
    "- More on this in: splitting.ipynb "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42)"
   ]
  },
  {
   "source": [
    "# Transformation of Categorical and Numeric Features\n",
    "- combining preprocessing steps of both categorical and numeric data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within the ColumnTransformer function, a list function of (\"name\", preprocessing function, columns to be transformed)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(sparse=False), [\"Pclass\", \"Sex\"]),\n",
    "    (\"scaling\", StandardScaler(),[\"Fare\"])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        -0.0325683 ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        -0.48733085],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "        -0.34285405],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        -0.35045024],\n",
       "       [ 1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         1.7030926 ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.8747751 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "#.fit_transform is the chain method of .fit and .transform putting together\n",
    "#.fit_transform is used on the train train dataset\n",
    "\n",
    "X_train_fit_trans = ct.fit_transform(X_train)\n",
    "X_train_fit_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        -0.32839086],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "        -0.42042549],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        -0.4703621 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        -0.47092837],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "        -0.37194334],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        -0.23207234]])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_test_trans = ct.transform(X_test)\n",
    "X_test_trans"
   ]
  },
  {
   "source": [
    "# For curiosity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/royceto/anaconda3/envs/myenv/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "logreg.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7757847533632287"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "logreg.score(X_test_trans, y_test)"
   ]
  }
 ]
}