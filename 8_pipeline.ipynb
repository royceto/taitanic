{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd000fbe7a0ffdff41cb6153984e119c63b68f43f50190a26a2d6b6229a722be293",
   "display_name": "Python 3.7.10 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Pipeline\n",
    "\n",
    "https://towardsdatascience.com/pipeline-columntransformer-and-featureunion-explained-f5491f815f\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general use and reading in the data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#spliting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Feature Union\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "\n",
    "#models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "source": [
    "## 1. Reading in the data\n",
    "## 2. Features and target selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "data = os.path.join(pwd, \"data.csv\")\n",
    "df = pd.read_csv(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "## 3. X, y selection and Spliting Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[\"Pclass\", \"Sex\", \"Fare\"]]\n",
    "target = df[[\"Survived\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,target, stratify=target)"
   ]
  },
  {
   "source": [
    "## 4. Preprocessing and Pipeline\n",
    "\n",
    "- Pipeline: during the call to *Pipline.fit*, the pipeline calls *fit* and then *transform* on each step in turn, with the input given by the output of the *transform* method of the previous step.\n",
    "- for the last step in the pipeline. just *fit* is called"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"Pclass\", \"Sex\"]\n",
    "numerical = [\"Fare\"]\n",
    "\n",
    "#categorical pipeline\n",
    "cat_pipe = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "])\n",
    "\n",
    "#numerical pipeline\n",
    "num_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "#ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_pipe\", cat_pipe, categorical),\n",
    "        (\"num_pipe\", num_pipe, numerical)\n",
    "        ]\n",
    ")\n",
    "\n",
    "#pipline preprocessor + model\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"svm\", SVC())\n",
    "        #(\"dummy\", DummyClassifier())\n",
    "        #(\"logreg\", LogisticRegression())\n",
    "        #(\"knn\", KNeighborsClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.fit(X_train, np.ravel(y_train))\n",
    "# pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat_pipe',\n",
       "                                                                         Pipeline(steps=[('encoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         ['Pclass',\n",
       "                                                                          'Sex']),\n",
       "                                                                        ('num_pipe',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['Fare'])])),\n",
       "                                       ('svm', SVC())]),\n",
       "             param_grid={'svm__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'svm__gamma': [0.001, 0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "metadata": {},
     "execution_count": 239
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"svm__C\":[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"svm__gamma\":[0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid_svm.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTest set score: 0.84\n\nBest cross-validation score: 0.80\nBest parameters: {'svm__C': 100, 'svm__gamma': 0.1}\nBest best_estimator_: SVC(C=100, gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\\nTest set score: {:.2f}\\n\".format(grid_svm.score(X_test, y_test))\n",
    ")\n",
    "print(\n",
    "    \"Best cross-validation score: {:.2f}\".format(grid_svm.best_score_)\n",
    ")\n",
    "print(\n",
    "    \"Best parameters: {}\".format(grid_svm.best_params_)\n",
    ")\n",
    "print(\n",
    "    \"Best best_estimator_: {}\".format(grid_svm.best_estimator_.named_steps[\"svm\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('cat_pipe',\n",
       "                                 Pipeline(steps=[('encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False))]),\n",
       "                                 ['Pclass', 'Sex']),\n",
       "                                ('num_pipe',\n",
       "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                 ['Fare'])])"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "pipe.steps[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([\n",
    "    (\"preprocessing\", StandardScaler()),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = [\n",
    "    {\"classifier\":[SVC()],\"preprocessing\":[StandardScaler(),None], \"classifier__gamma\":[0.001, 0.01, 0.1, 1, 10, 100],\"classifier__C\":[0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "    {\"classifier\":[RandomForestClassifier(n_estimators=100)],\"preprocessing\":[None],\"classifier__max_features\":[1,2,3]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(cancer.data, cancer.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessing', StandardScaler()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid=[{'classifier': [SVC(C=10, gamma=0.01)],\n",
       "                          'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                          'preprocessing': [StandardScaler(), None]},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__max_features': [1, 2, 3],\n",
       "                          'preprocessing': [None]}])"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "grid2 =GridSearchCV(pipe2, param_grid=param_grid2, cv=5)\n",
    "grid2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params:\n{'classifier': SVC(C=10, gamma=0.01), 'classifier__C': 10, 'classifier__gamma': 0.01, 'preprocessing': StandardScaler()}\n\nBest cross-validaiton score: 0.99\nTest-set score: 0.838565\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Best params:\\n{}\\n\".format(grid2.best_params_)\n",
    ")\n",
    "print(\n",
    "    \"Best cross-validaiton score: {:.2f}\".format(grid2.best_score_)\n",
    ")\n",
    "print(\n",
    "    \"Test-set score: {:2f}\".format(grid.score(X_test, y_test))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}