{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd000fbe7a0ffdff41cb6153984e119c63b68f43f50190a26a2d6b6229a722be293",
   "display_name": "Python 3.7.10 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Spliting a Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#for spliting a dataset into training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#randomise KFold in cross-validaiton\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#machine learning model for Cross-Validation\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "data = os.path.join(pwd, \"data.csv\")\n",
    "df = pd.read_csv(data)\n",
    "df.head(3)"
   ]
  },
  {
   "source": [
    "### Feature and target selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[[\"Pclass\", \"Sex\",\"Fare\"]]\n",
    "target = df[[\"Survived\"]]\n",
    "\n",
    "target_np = target.to_numpy()"
   ]
  },
  {
   "source": [
    "# Splitting Dataset\n",
    "\n",
    "- There are two weays to split a dataset:\n",
    "    - spliting a dataset into 2 (see Method 1)\n",
    "    - spliting a dataset by kfold (see Method 2)\n",
    "- Both methods will be used throughout machine learning, not one better than the other but situational\n",
    "\n",
    "\n",
    "## Method 1: train_test_split\n",
    "- a simple splitting method to divide a dataset into 2 by proportion\n",
    "- proportionally, a dataset is divided between 0.75 (X_train, y_train) and 0.25 (X_test, y_test)\n",
    "- use argument test_size= *float or int* for changing the proportion\n",
    "- use argument stratify=target to make sure proportional target is splitted across datasets, especially when a target is much larger than the other \n",
    "- remember that the test set (i.e. X_test, y_test) should always be reserved as unseen dataset for the final evaluation of the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Pclass     Sex    Fare  Survived\n",
       "486       1  female  90.000         1\n",
       "238       2    male  10.500         0\n",
       "722       2    male  13.000         0\n",
       "184       3  female  22.025         1\n",
       "56        2  female  10.500         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Fare</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>486</th>\n      <td>1</td>\n      <td>female</td>\n      <td>90.000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>2</td>\n      <td>male</td>\n      <td>10.500</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>722</th>\n      <td>2</td>\n      <td>male</td>\n      <td>13.000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>3</td>\n      <td>female</td>\n      <td>22.025</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>2</td>\n      <td>female</td>\n      <td>10.500</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42, stratify=target)\n",
    "\n",
    "#merging the training of features and target datasets together\n",
    "X_train_y_train = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "X_train_y_train.head()"
   ]
  },
  {
   "source": [
    "- Kind in mind that a given dataset for machine learning should be divided into three dataset, i.e.:\n",
    "    a. training set\n",
    "    b. validaiton set\n",
    "    c. test set\n",
    "    \n",
    "- reasons:\n",
    "    - use a. training set to build the model\n",
    "    - use b. validaiton set to select the parameters of the model\n",
    "    - use c. test set to evaluate the performace of the selected parameters (confusion matrics and all the good stuff)\n",
    "    - use a. training set and b. validation set wht parameters tested on c. test set to evaluate performace (use as much data as possible)\n",
    "\n",
    "- While some of the coding methods could obmit splittting a dataset 3 times manually (GridSearchCV), beaware of which dataset was used during machine trainig development could affect the final result.\n",
    "\n",
    "- always reserve X_test and y_test for evaluation, cos the next set of data to put in .predict will be truely unseen data, better be good!\n",
    "\n",
    "- the following code explicitly divided a dataset into 3 sets. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the whole dataset into trainval set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(features, target, random_state=0, stratify=target)\n",
    "\n",
    "# within trainval set, split it into train set and valid set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1, stratify=y_trainval)"
   ]
  },
  {
   "source": [
    "## Method 2: Cross-Validation (CV)\n",
    "- regarding cv, read here: https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f\n",
    "- a model is required, hence preprocessing is needed for non-numeric values\n",
    "- spliting of dataset is may or many not  be randomised (e.g. use KFold to randomise)\n",
    "\n",
    "### Some of the benefits:\n",
    "- X and y will  be thoroughly tested under k number of fold, better generalisation of a model can be produced.\n",
    "- Utilisation of a dataset: train\\_test\\_split divide a dataset by 1 time (between 75% and 25%, as default) for training and evaluation. Where cross-validation divide a dataset into several subset for training and testing (k-fold, as in cv=5).\n",
    "- Cross-validation produce a range of scores to indicate the performance of a model in its best and worst case scenarios to new data.  \n",
    "\n",
    "### Drawback:\n",
    "- Computational cost, need to train k models instead of a single model. \n",
    "\t- Personal option: given the speed and efficiency of modern cpu and relatively manageable data size (thousand of rows, dozen of columns max), this drawback should be manageable.  \n",
    "\n",
    "### Caution:\n",
    "- Cross-validation  is not a way to build a model that can be applied to new data.\n",
    "\t- Does not return a model\n",
    "\t- Use for evaluating how well a given algorithm will generalise when trained on a specific dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#transformer\n",
    "ct = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(sparse=False), [\"Pclass\", \"Sex\"]),\n",
    "    (\"scaling\", StandardScaler(),[\"Fare\"])\n",
    "    ])\n",
    "\n",
    "#.fit_transform to X_train\n",
    "X_train_fit_trans = ct.fit_transform(features)\n",
    "\n",
    "# here we used the full dataset, in real word situation a \"test set (X_test, y_test) should be reserved for test\"\n",
    "# X_train_fit_trans = ct.fit_transform(X_train)"
   ]
  },
  {
   "source": [
    "## Standard KFold - cross_val_score\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.79329609, 0.80337079, 0.76966292, 0.75842697, 0.78651685])"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "score = cross_val_score(logreg, X_train_fit_trans, np.ravel(target), cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7822547234950725"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "source": [
    "## Standard KFold - cross_validate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  0.006605    0.000365    0.793296     0.779494\n1  0.006318    0.000294    0.803371     0.785414\n2  0.004639    0.000372    0.769663     0.785414\n3  0.003547    0.000294    0.758427     0.796634\n4  0.006408    0.000403    0.786517     0.786816",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.006605</td>\n      <td>0.000365</td>\n      <td>0.793296</td>\n      <td>0.779494</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.006318</td>\n      <td>0.000294</td>\n      <td>0.803371</td>\n      <td>0.785414</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.004639</td>\n      <td>0.000372</td>\n      <td>0.769663</td>\n      <td>0.785414</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.003547</td>\n      <td>0.000294</td>\n      <td>0.758427</td>\n      <td>0.796634</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.006408</td>\n      <td>0.000403</td>\n      <td>0.786517</td>\n      <td>0.786816</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "res = cross_validate(logreg, X_train_fit_trans, np.ravel(target), cv=5, return_train_score=True)\n",
    "res_df = pd.DataFrame(res)\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7822547234950725"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "res[\"test_score\"].mean()"
   ]
  },
  {
   "source": [
    "## Stratified k-Fold Cross-Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7822547234950725"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "score_kf = cross_val_score(logreg, X_train_fit_trans, np.ravel(target), cv=kf)\n",
    "score_kf.mean()"
   ]
  },
  {
   "source": [
    "## Randomise CV with KFold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.78212291, 0.76404494, 0.83707865, 0.74719101, 0.80337079])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "score_kfold = cross_val_score(logreg, X_fit_trans, np.ravel(target), cv=kfold)\n",
    "score_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.786761659657272"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "score_kfold.mean()"
   ]
  },
  {
   "source": [
    "## Leave-one-out cross-validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "score_loo = cross_val_score(logreg, X_train_fit_trans, np.ravel(target), cv=loo)\n",
    "\n",
    "len(score_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7833894500561167"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "score_loo.mean()"
   ]
  },
  {
   "source": [
    "## Shuffle-split cross-validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.76681614, 0.75784753, 0.77802691, 0.79596413, 0.80493274,\n",
       "       0.76233184, 0.78699552, 0.77130045, 0.77578475, 0.78475336])"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(logreg, X_train_fit_trans, np.ravel(target), cv=shuffle_split)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7784753363228699"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "scores.mean()"
   ]
  }
 ]
}