{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd000fbe7a0ffdff41cb6153984e119c63b68f43f50190a26a2d6b6229a722be293",
   "display_name": "Python 3.7.10 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Spliting a Dataset\n",
    "- A dataet will need to split into 3 to develop a model:\n",
    "    - **Training Set:** To build the model\n",
    "    - **Validation Set:** To select the parameters of the model\n",
    "    - **Test Set:** To evaluate the performace of selected parameters\n",
    "- While some functions could obmit splitting a dataet into 3 by cross-validaiton, always remember to keep a set of unseen data (X_test, y_test) for testing your model.\n",
    "\n",
    "In sklearn, there are 2 ways to split your data, i.e.:\n",
    "- Method 1: train_test_split\n",
    "- Method 2: Cross-validation(CV)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for spliting a dataset into training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#similar to cross_val_score but with time\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#for imbalanced target to be reflected in each fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#randomise KFold in cross-validaiton\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Leave-one-out cross-validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "#Shuffle-split cross-validaiton\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "source": [
    "## - Reading in the data\n",
    "## - Features and target selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "data= os.path.join(pwd, \"data.csv\")\n",
    "df = pd.read_csv(data)\n",
    "features = df[[\"Pclass\", \"Sex\", \"Fare\"]]\n",
    "target = df[[\"Survived\"]]"
   ]
  },
  {
   "source": [
    "# Method 1: train_test_split\n",
    "- a simple splitting function to divide a dataset into 2 by proportion\n",
    "- by default, a dataset is divided between 0.75 (X_train, y_train) and 0.25 (X_test, y_test)\n",
    "- use argument test_size= *float or int* for changing the proportion\n",
    "- use argument stratify=target to make sure proportional target is splitted across datasets, especially when a target is much smaller than the other \n",
    "- remember that the test set (i.e. X_test, y_test) should always be reserved as an unseen dataset for the final evaluation of the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Pclass     Sex    Fare  Survived\n",
       "486       1  female  90.000         1\n",
       "238       2    male  10.500         0\n",
       "722       2    male  13.000         0\n",
       "184       3  female  22.025         1\n",
       "56        2  female  10.500         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Fare</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>486</th>\n      <td>1</td>\n      <td>female</td>\n      <td>90.000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>2</td>\n      <td>male</td>\n      <td>10.500</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>722</th>\n      <td>2</td>\n      <td>male</td>\n      <td>13.000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>3</td>\n      <td>female</td>\n      <td>22.025</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>2</td>\n      <td>female</td>\n      <td>10.500</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=42, stratify=target)\n",
    "\n",
    "#merging the training of features and target datasets together\n",
    "X_train_y_train = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "X_train_y_train.head()"
   ]
  },
  {
   "source": [
    "- To explicitly divided a dataset into 3, we first divide a dataset into two as trainval (X_trainval, ytrainval) and test (X_test and y_test).\n",
    "\n",
    "- After that, datasets of trainval will split again into train (X_train and y_train) and valid (y_train and y_valid) datasets\n",
    "\n",
    "hence, the folloing code:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the whole dataset into trainval set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(features, target, random_state=0, stratify=target)\n",
    "\n",
    "# within trainval set, split it into train set and valid set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=0, stratify=y_trainval)"
   ]
  },
  {
   "source": [
    "# Method 2: Cross-Validation (CV)\n",
    "\n",
    "## Method 2: Cross-Validation (CV)\n",
    "- regarding cv, read here: https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f\n",
    "- a model is required, hence preprocessing is needed for non-numeric values\n",
    "- spliting of dataset is may or many not  be randomised (e.g. use KFold to randomise)\n",
    "\n",
    "### Some of the benefits:\n",
    "- X and y will  be thoroughly tested under k number of fold, better generalisation of a model can be produced.\n",
    "- Utilisation of a dataset: train\\_test\\_split divide a dataset by 1 time (between 75% and 25%, as default) for training and evaluation. Where cross-validation divide a dataset into several subset for training and testing (k-fold, as in cv=5).\n",
    "- Cross-validation produce a range of scores to indicate the performance of a model in its best and worst case scenarios to new data.  \n",
    "\n",
    "### Drawback:\n",
    "- Computational cost, need to train k models instead of a single model. \n",
    "\t- Personal option: given the speed and efficiency of modern cpu and relatively manageable data size (thousand of rows, dozen of columns max), this drawback should be manageable.  \n",
    "\n",
    "### Caution:\n",
    "- Cross-validation  is not a way to build a model that can be applied to new data.\n",
    "- Does not return a model\n",
    "- Use for evaluating how well a given algorithm will generalise when trained on a specific dataset. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#transformer\n",
    "ct = ColumnTransformer([\n",
    "    (\"onehot\", OneHotEncoder(sparse=False), [\"Pclass\", \"Sex\"]),\n",
    "    (\"scaling\", StandardScaler(),[\"Fare\"])\n",
    "    ])\n",
    "\n",
    "#.fit_transform to X_train\n",
    "X_trainval_fit_trans = ct.fit_transform(X_trainval)"
   ]
  },
  {
   "source": [
    "There are quite a lot of cross-validaiton funcitons, the following listed a few:  \n",
    "\n",
    "1. Standard KFold (cross_val_score and cross_validate)\n",
    "2. Stratified k-Fold Cross Validaiton - especailly useful when one or more targets are much smaller than the others\n",
    "3. Cross Validation with KFold (use KFold funciton to fit into cv argument, more control on kfold, e.g. randomise the dataset before splitting)\n",
    "4. Leave-one-out Cross Validation (1 target vs rest of the dataset in each Fold)\n",
    "5. Shuffle-split Cross Validation (select a portion for train test on each split)\n",
    "\n",
    "Normally, item 1 and 2 are good enough for using\n",
    "\n",
    "(cross-validaiton with groups is not listed here)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Standard KFold - cross_val_score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.7761194 , 0.80597015, 0.82835821, 0.78195489, 0.7443609 ])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "score = cross_val_score(logreg, X_trainval_fit_trans, np.ravel(y_trainval), cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7873527101335428"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "source": [
    "## Starndard KFold - cross_validate \n",
    "- similar to cross_val_socre but with time\n",
    "\n",
    "(check what's train_score)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   fit_time  score_time  test_score  train_score\n0  0.004553    0.000304    0.776119     0.790262\n1  0.004591    0.000287    0.805970     0.782772\n2  0.005341    0.000320    0.828358     0.777154\n3  0.004668    0.000250    0.781955     0.788785\n4  0.003966    0.000246    0.744361     0.798131",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.004553</td>\n      <td>0.000304</td>\n      <td>0.776119</td>\n      <td>0.790262</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004591</td>\n      <td>0.000287</td>\n      <td>0.805970</td>\n      <td>0.782772</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.005341</td>\n      <td>0.000320</td>\n      <td>0.828358</td>\n      <td>0.777154</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004668</td>\n      <td>0.000250</td>\n      <td>0.781955</td>\n      <td>0.788785</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.003966</td>\n      <td>0.000246</td>\n      <td>0.744361</td>\n      <td>0.798131</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "res = cross_validate(logreg, X_trainval_fit_trans, np.ravel(y_trainval), cv=5, return_train_score=True)\n",
    "res_df = pd.DataFrame(res)\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7873527101335428"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "res[\"test_score\"].mean()"
   ]
  },
  {
   "source": [
    "## Stratified k-Fold Cross-Validaiton\n",
    "- imbalance of target, i.e. one result is much larger/smaller than the other, should be reflected in each Fold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7873527101335428"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "score_kf = cross_val_score(logreg, X_trainval_fit_trans, np.ravel(y_trainval), cv=kf)\n",
    "score_kf.mean()"
   ]
  },
  {
   "source": [
    "## Cross Validation with KFold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7872908186341022"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "#shuffled the data using arguments shuffle=True, random_state=42\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "score_kfold = cross_val_score(logreg, X_trainval_fit_trans, np.ravel(y_trainval), cv=kfold)\n",
    "score_kfold.mean()"
   ]
  },
  {
   "source": [
    "## Leave-one-out Cross-Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "score_loo = cross_val_score(logreg, X_trainval_fit_trans, np.ravel(y_trainval), cv=loo)\n",
    "\n",
    "len(score_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7874251497005988"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "score_loo.mean()"
   ]
  },
  {
   "source": [
    "## Shuffle-split Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.80239521, 0.79041916, 0.79640719, 0.77245509, 0.76347305,\n",
       "       0.78742515, 0.76946108, 0.75149701, 0.79341317, 0.78443114])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.2, n_splits=10)\n",
    "scores = cross_val_score(logreg, X_trainval_fit_trans, np.ravel(y_trainval), cv=shuffle_split)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7811377245508981"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "scores.mean()"
   ]
  }
 ]
}